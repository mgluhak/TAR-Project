{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import dataset_map_entry\n",
    "import sys\n",
    "import pickle\n",
    "import os\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import csv\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_dataset():\n",
    "    input_dataset = open('./output/map_final.pkl', 'rb')\n",
    "    dataset = pickle.load(input_dataset)\n",
    "    input_dataset.close()\n",
    "\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# custom spliter used instead of a tokenizer, since the tweets are already tokenized\n",
    "def spaceSplitter(list):\n",
    "    return list.split(\" \")\n",
    "\n",
    "def getFeatures(dataset, classification=\"both\"):\n",
    "    documents = []\n",
    "    y = []\n",
    "\n",
    "    # lemmatizer = WordNetLemmatizer()\n",
    "    # stemmer = SnowballStemmer('english')\n",
    "\n",
    "    # joining tokens with whitespace in order to fit the tf-idf vectorizer\n",
    "    for user in sorted(dataset.keys()):\n",
    "        tweets = dataset[user].get_tweets()\n",
    "        if classification == \"both\":\n",
    "            y.append(str(dataset[user].get_gender().value) + str(dataset[user].get_age_group().value))\n",
    "        elif classification == \"gender\":\n",
    "            y.append(str(dataset[user].get_gender().value))\n",
    "        elif classification == \"age\":\n",
    "            y.append(str(dataset[user].get_age_group().value))\n",
    "        else:\n",
    "            raise ValueError(\"Given clasification taks is not specified\")\n",
    "\n",
    "        document = []\n",
    "        for tweet in tweets:\n",
    "            # taggedTweet = nltk.pos_tag(tweet)\n",
    "            # lemmatizedTweet = map( lambda x : lemmatizer.lemmatize(x[0], penn_to_wn(x[1])) , taggedTweet)\n",
    "            # stemmedTweet = map( lambda x : stemmer.stem(x) , tweet)\n",
    "            # document.append(\" \".join(stemmedTweet))\n",
    "            document.append(\" \".join(tweet))\n",
    "        documents.append(\" \".join(document))\n",
    "\n",
    "    ## Definining tf-idf vector\n",
    "\n",
    "    vectorizer = TfidfVectorizer(tokenizer=spaceSplitter)\n",
    "    vectorizer.fit(documents)\n",
    "\n",
    "    features = vectorizer.transform(documents)\n",
    "    names = vectorizer.get_feature_names()\n",
    "    \n",
    "    return features, y, names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ds = load_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "features_age, y_age, names = getFeatures(dataset=ds, classification='age')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "436\n",
      "436\n",
      "252169\n",
      "436\n",
      "  (0, 0)\t0.0\n",
      "  (1, 0)\t0.0\n",
      "  (2, 0)\t0.0\n",
      "  (3, 0)\t0.0\n",
      "  (4, 0)\t0.0\n",
      "  (5, 0)\t0.0\n",
      "  (6, 0)\t0.0\n",
      "  (7, 0)\t0.0\n",
      "  (8, 0)\t0.0\n",
      "  (9, 0)\t0.0\n",
      "  (10, 0)\t0.0\n",
      "  (11, 0)\t0.0\n",
      "  (12, 0)\t0.0\n",
      "  (13, 0)\t0.0\n",
      "  (14, 0)\t0.0\n",
      "  (15, 0)\t0.0\n",
      "  (16, 0)\t0.0\n",
      "  (17, 0)\t0.0\n",
      "  (18, 0)\t0.0\n",
      "  (19, 0)\t0.0\n",
      "  (20, 0)\t0.0\n",
      "  (21, 0)\t0.0\n",
      "  (22, 0)\t0.0\n",
      "  (23, 0)\t0.0\n",
      "  (24, 0)\t0.0\n",
      "  :\t:\n",
      "  (411, 0)\t0.0\n",
      "  (412, 0)\t0.0\n",
      "  (413, 0)\t0.0\n",
      "  (414, 0)\t0.0\n",
      "  (415, 0)\t0.0\n",
      "  (416, 0)\t0.0\n",
      "  (417, 0)\t0.0\n",
      "  (418, 0)\t0.0\n",
      "  (419, 0)\t0.0\n",
      "  (420, 0)\t0.0\n",
      "  (421, 0)\t0.0\n",
      "  (422, 0)\t0.0\n",
      "  (423, 0)\t0.0\n",
      "  (424, 0)\t0.0\n",
      "  (425, 0)\t0.0\n",
      "  (426, 0)\t0.0\n",
      "  (427, 0)\t0.0\n",
      "  (428, 0)\t0.0\n",
      "  (429, 0)\t0.0\n",
      "  (430, 0)\t0.0\n",
      "  (431, 0)\t0.0\n",
      "  (432, 0)\t0.0\n",
      "  (433, 0)\t0.0\n",
      "  (434, 0)\t0.0\n",
      "  (435, 0)\t0.0\n",
      "436\n",
      "  (0, 0)\t0.0\n",
      "  (1, 0)\t0.0\n",
      "  (2, 0)\t0.0\n",
      "  (3, 0)\t0.0\n",
      "  (4, 0)\t0.0\n",
      "  (5, 0)\t0.0\n",
      "  (6, 0)\t0.0\n",
      "  (7, 0)\t0.0\n",
      "  (8, 0)\t0.0\n",
      "  (9, 0)\t0.0\n",
      "  (10, 0)\t0.0\n",
      "  (11, 0)\t0.0\n",
      "  (12, 0)\t0.0\n",
      "  (13, 0)\t0.0\n",
      "  (14, 0)\t0.0\n",
      "  (15, 0)\t0.0\n",
      "  (16, 0)\t0.0\n",
      "  (17, 0)\t0.0\n",
      "  (18, 0)\t0.0\n",
      "  (19, 0)\t0.0\n",
      "  (20, 0)\t0.0\n",
      "  (21, 0)\t0.0\n",
      "  (22, 0)\t0.0\n",
      "  (23, 0)\t0.0\n",
      "  (24, 0)\t0.0\n",
      "  :\t:\n",
      "  (411, 0)\t0.0\n",
      "  (412, 0)\t0.0\n",
      "  (413, 0)\t0.0\n",
      "  (414, 0)\t0.0\n",
      "  (415, 0)\t0.0\n",
      "  (416, 0)\t0.0\n",
      "  (417, 0)\t0.0\n",
      "  (418, 0)\t0.0\n",
      "  (419, 0)\t0.0\n",
      "  (420, 0)\t0.0\n",
      "  (421, 0)\t0.0\n",
      "  (422, 0)\t0.0\n",
      "  (423, 0)\t0.0\n",
      "  (424, 0)\t0.0\n",
      "  (425, 0)\t0.0\n",
      "  (426, 0)\t0.0\n",
      "  (427, 0)\t0.0\n",
      "  (428, 0)\t0.0\n",
      "  (429, 0)\t0.0\n",
      "  (430, 0)\t0.0\n",
      "  (431, 0)\t0.0\n",
      "  (432, 0)\t0.0\n",
      "  (433, 0)\t0.0\n",
      "  (434, 0)\t0.0\n",
      "  (435, 0)\t0.0\n",
      "436\n",
      "  (0, 0)\t0.0\n",
      "  (1, 0)\t0.0\n",
      "  (2, 0)\t0.0\n",
      "  (3, 0)\t0.0\n",
      "  (4, 0)\t0.0\n",
      "  (5, 0)\t0.0\n",
      "  (6, 0)\t0.0\n",
      "  (7, 0)\t0.0\n",
      "  (8, 0)\t0.0\n",
      "  (9, 0)\t0.0\n",
      "  (10, 0)\t0.0\n",
      "  (11, 0)\t0.0\n",
      "  (12, 0)\t0.0\n",
      "  (13, 0)\t0.0\n",
      "  (14, 0)\t0.0\n",
      "  (15, 0)\t0.0\n",
      "  (16, 0)\t0.0\n",
      "  (17, 0)\t0.0\n",
      "  (18, 0)\t0.0\n",
      "  (19, 0)\t0.0\n",
      "  (20, 0)\t0.0\n",
      "  (21, 0)\t0.0\n",
      "  (22, 0)\t0.0\n",
      "  (23, 0)\t0.0\n",
      "  (24, 0)\t0.0\n",
      "  :\t:\n",
      "  (411, 0)\t0.0\n",
      "  (412, 0)\t0.0\n",
      "  (413, 0)\t0.0\n",
      "  (414, 0)\t0.0\n",
      "  (415, 0)\t0.0\n",
      "  (416, 0)\t0.0\n",
      "  (417, 0)\t0.0\n",
      "  (418, 0)\t0.0\n",
      "  (419, 0)\t0.0\n",
      "  (420, 0)\t0.0\n",
      "  (421, 0)\t0.0\n",
      "  (422, 0)\t0.0\n",
      "  (423, 0)\t0.0\n",
      "  (424, 0)\t0.0\n",
      "  (425, 0)\t0.0\n",
      "  (426, 0)\t0.0\n",
      "  (427, 0)\t0.0\n",
      "  (428, 0)\t0.0\n",
      "  (429, 0)\t0.0\n",
      "  (430, 0)\t0.0\n",
      "  (431, 0)\t0.0\n",
      "  (432, 0)\t0.0\n",
      "  (433, 0)\t0.0\n",
      "  (434, 0)\t0.0\n",
      "  (435, 0)\t0.0\n",
      "436\n",
      "  (0, 0)\t0.0\n",
      "  (1, 0)\t0.0\n",
      "  (2, 0)\t0.0\n",
      "  (3, 0)\t0.0\n",
      "  (4, 0)\t0.0\n",
      "  (5, 0)\t0.0\n",
      "  (6, 0)\t0.0\n",
      "  (7, 0)\t0.0\n",
      "  (8, 0)\t0.0\n",
      "  (9, 0)\t0.0\n",
      "  (10, 0)\t0.0\n",
      "  (11, 0)\t0.0\n",
      "  (12, 0)\t0.0\n",
      "  (13, 0)\t0.0\n",
      "  (14, 0)\t0.0\n",
      "  (15, 0)\t0.0\n",
      "  (16, 0)\t0.0\n",
      "  (17, 0)\t0.0\n",
      "  (18, 0)\t0.0\n",
      "  (19, 0)\t0.0\n",
      "  (20, 0)\t0.0\n",
      "  (21, 0)\t0.0\n",
      "  (22, 0)\t0.0\n",
      "  (23, 0)\t0.0\n",
      "  (24, 0)\t0.0\n",
      "  :\t:\n",
      "  (411, 0)\t0.0\n",
      "  (412, 0)\t0.0\n",
      "  (413, 0)\t0.0\n",
      "  (414, 0)\t0.0\n",
      "  (415, 0)\t0.0\n",
      "  (416, 0)\t0.0\n",
      "  (417, 0)\t0.0\n",
      "  (418, 0)\t0.0\n",
      "  (419, 0)\t0.0\n",
      "  (420, 0)\t0.0\n",
      "  (421, 0)\t0.0\n",
      "  (422, 0)\t0.0\n",
      "  (423, 0)\t0.0\n",
      "  (424, 0)\t0.0\n",
      "  (425, 0)\t0.0\n",
      "  (426, 0)\t0.0\n",
      "  (427, 0)\t0.0\n",
      "  (428, 0)\t0.0\n",
      "  (429, 0)\t0.0\n",
      "  (430, 0)\t0.0\n",
      "  (431, 0)\t0.0\n",
      "  (432, 0)\t0.0\n",
      "  (433, 0)\t0.0\n",
      "  (434, 0)\t0.0\n",
      "  (435, 0)\t0.0\n",
      "436\n",
      "  (0, 0)\t0.0\n",
      "  (1, 0)\t0.0\n",
      "  (2, 0)\t0.0\n",
      "  (3, 0)\t0.0\n",
      "  (4, 0)\t0.0\n",
      "  (5, 0)\t0.0\n",
      "  (6, 0)\t0.0\n",
      "  (7, 0)\t0.0\n",
      "  (8, 0)\t0.0\n",
      "  (9, 0)\t0.0\n",
      "  (10, 0)\t0.0\n",
      "  (11, 0)\t0.0\n",
      "  (12, 0)\t0.0\n",
      "  (13, 0)\t0.0\n",
      "  (14, 0)\t0.0\n",
      "  (15, 0)\t0.0\n",
      "  (16, 0)\t0.0\n",
      "  (17, 0)\t0.0\n",
      "  (18, 0)\t0.0\n",
      "  (19, 0)\t0.0\n",
      "  (20, 0)\t0.0\n",
      "  (21, 0)\t0.0\n",
      "  (22, 0)\t0.0\n",
      "  (23, 0)\t0.0\n",
      "  (24, 0)\t0.0\n",
      "  :\t:\n",
      "  (411, 0)\t0.0\n",
      "  (412, 0)\t0.0\n",
      "  (413, 0)\t0.0\n",
      "  (414, 0)\t0.0\n",
      "  (415, 0)\t0.0\n",
      "  (416, 0)\t0.0\n",
      "  (417, 0)\t0.0\n",
      "  (418, 0)\t0.0\n",
      "  (419, 0)\t0.0\n",
      "  (420, 0)\t0.0\n",
      "  (421, 0)\t0.0\n",
      "  (422, 0)\t0.0\n",
      "  (423, 0)\t0.0\n",
      "  (424, 0)\t0.0\n",
      "  (425, 0)\t0.0\n",
      "  (426, 0)\t0.0\n",
      "  (427, 0)\t0.0\n",
      "  (428, 0)\t0.0\n",
      "  (429, 0)\t0.0\n",
      "  (430, 0)\t0.0\n",
      "  (431, 0)\t0.0\n",
      "  (432, 0)\t0.0\n",
      "  (433, 0)\t0.0\n",
      "  (434, 0)\t0.0\n",
      "  (435, 0)\t0.0\n",
      "436\n",
      "  (0, 0)\t0.0\n",
      "  (1, 0)\t0.0\n",
      "  (2, 0)\t0.0\n",
      "  (3, 0)\t0.0\n",
      "  (4, 0)\t0.0\n",
      "  (5, 0)\t0.0\n",
      "  (6, 0)\t0.0\n",
      "  (7, 0)\t0.0\n",
      "  (8, 0)\t0.0\n",
      "  (9, 0)\t0.0\n",
      "  (10, 0)\t0.0\n",
      "  (11, 0)\t0.0\n",
      "  (12, 0)\t0.0\n",
      "  (13, 0)\t0.0\n",
      "  (14, 0)\t0.0\n",
      "  (15, 0)\t0.0\n",
      "  (16, 0)\t0.0\n",
      "  (17, 0)\t0.0\n",
      "  (18, 0)\t0.0\n",
      "  (19, 0)\t0.0\n",
      "  (20, 0)\t0.0\n",
      "  (21, 0)\t0.0\n",
      "  (22, 0)\t0.0\n",
      "  (23, 0)\t0.0\n",
      "  (24, 0)\t0.0\n",
      "  :\t:\n",
      "  (411, 0)\t0.0\n",
      "  (412, 0)\t0.0\n",
      "  (413, 0)\t0.0\n",
      "  (414, 0)\t0.0\n",
      "  (415, 0)\t0.0\n",
      "  (416, 0)\t0.0\n",
      "  (417, 0)\t0.0\n",
      "  (418, 0)\t0.0\n",
      "  (419, 0)\t0.0\n",
      "  (420, 0)\t0.0\n",
      "  (421, 0)\t0.0\n",
      "  (422, 0)\t0.0\n",
      "  (423, 0)\t0.0\n",
      "  (424, 0)\t0.0\n",
      "  (425, 0)\t0.0\n",
      "  (426, 0)\t0.0\n",
      "  (427, 0)\t0.0\n",
      "  (428, 0)\t0.0\n",
      "  (429, 0)\t0.0\n",
      "  (430, 0)\t0.0\n",
      "  (431, 0)\t0.0\n",
      "  (432, 0)\t0.0\n",
      "  (433, 0)\t0.0\n",
      "  (434, 0)\t0.0\n",
      "  (435, 0)\t0.0\n"
     ]
    }
   ],
   "source": [
    "print(len(features_age.todense()))\n",
    "print(len(y_age))\n",
    "print(len(names))\n",
    "i = 0\n",
    "for name in names:\n",
    "    column = names.index(name)\n",
    "    print(len(features_age[:, column].todense()))\n",
    "    features_age[:, column] = 0\n",
    "    print(features_age[:, column])\n",
    "    i += 1\n",
    "    if i > 5:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"./output/age_features.csv\", \"w\") as file:\n",
    "    writer = csv.writer(file, delimiter=\";\")\n",
    "    writer.writerow([\"UserId\", \"Phrase\", \"Score\", \"Class\"])\n",
    "    #writer.writerow([\"Score\", \"Class\"])\n",
    " \n",
    "    doc_id = 0\n",
    "    for doc, y in zip(features_age.todense(), y_age):\n",
    "        #print(\"Document %d\" %(doc_id))\n",
    "        word_id = 0\n",
    "        for score in doc.tolist()[0]:\n",
    "            if score > 0:\n",
    "                word = names[word_id].replace(\";\",\",\")\n",
    "                writer.writerow([doc_id+1, word_id, score, y])\n",
    "            word_id +=1\n",
    "        doc_id +=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame()\n",
    "\n",
    "for y in y_age:\n",
    "    df = df.append([[features_age[y], y]], ignore_index=True)\n",
    "\n",
    "df.columns = ['feature', 'class']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df.to_csv(path_or_buf='./output/age_features_tsv.tsv',sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
