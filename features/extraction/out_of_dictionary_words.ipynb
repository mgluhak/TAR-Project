{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import enchant\n",
    "import pickle\n",
    "import sys\n",
    "from Levenshtein.StringMatcher import StringMatcher\n",
    "import pyprind\n",
    "\n",
    "sys.path.insert(1, '../../dataset')\n",
    "import dataset_map_entry"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** 1. Method for loading dataset **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def load_dataset():\n",
    "    input_dataset = open('../../dataset/output/map_final.pkl', 'rb')\n",
    "    sys.modules['dataset_map_entry'] = dataset_map_entry\n",
    "    dataset = pickle.load(input_dataset)\n",
    "    input_dataset.close()\n",
    "\n",
    "    return dataset\n",
    "\n",
    "dataset = load_dataset()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** 2. Creating dictionary (and everything else that is necessary) for storing counts of 'out of dictionary words' with respect to the total number of words. **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# dictionary with english words\n",
    "d = enchant.Dict(\"en_US\")\n",
    "# dictionary with spanish words (because they may occurr in english tweets)\n",
    "d_sp = enchant.Dict(\"es\")\n",
    "# Tool for calculating Levenshtein word distance\n",
    "sm = StringMatcher()\n",
    "# List with out of dictionary words\n",
    "out_of_dict_words = set()\n",
    "# List with words in dictionary\n",
    "in_dict_words = set()\n",
    "# Levensthein word distance ratio threshold\n",
    "WORD_DIST_RATIO = 0.6\n",
    "#load brands\n",
    "brands = set(line.lower().strip() for line in open('brands.txt'))\n",
    "# dictionary with (user, (no_of_out_of_dict_words, total_no_of_words)) pair\n",
    "user_map = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** 3. Storing pairs (no_of_out_dict_words, total_no_of_words) in dictionary **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0%                          100%\n",
      "[##############################] | ETA: 00:00:00\n",
      "Total time elapsed: 00:03:37\n"
     ]
    }
   ],
   "source": [
    "pBar = pyprind.ProgBar(len(dataset))\n",
    "for user in dataset:\n",
    "    for tweet in dataset[user].tweets:\n",
    "        for word in tweet:\n",
    "            if word.replace('\\'','').replace('-','').isalpha() and not d.check(word) \\\n",
    "             and not d_sp.check(word) and (word not in brands) and ('URL' not in word) and ('NUMBER' not in word):\n",
    "                sm.set_seq1(seq1=word)\n",
    "                founded = False\n",
    "                for suggestion in d.suggest(word):\n",
    "                    sm.set_seq2(seq2=suggestion)\n",
    "                    if sm.ratio > WORD_DIST_RATIO:\n",
    "                        out_of_dict_words.add(word)\n",
    "                        founded = True\n",
    "                        break\n",
    "                if not founded:\n",
    "                    in_dict_words.add(word)\n",
    "            else:\n",
    "                in_dict_words.add(word)     \n",
    "    user_map[user] = (len(out_of_dict_words), len(out_of_dict_words) + len(in_dict_words))\n",
    "    out_of_dict_words.clear()\n",
    "    in_dict_words.clear()\n",
    "    pBar.update()            \n",
    "    \n",
    "                    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** 4. Storing dictionary in a file **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "output_dir = open('../pkls/out_of_dict_map.pkl', 'wb')\n",
    "pickle.dump(user_map, output_dir)\n",
    "output_dir.close()"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
